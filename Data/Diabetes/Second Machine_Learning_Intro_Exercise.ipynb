{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zHudEf8Au7Q"
      },
      "source": [
        "# Machine Learning Exercise\n",
        "\n",
        "Name:\n",
        "\n",
        "RegNo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ayiHpaPsAnVT"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zqnq_IiCA3TK"
      },
      "outputs": [],
      "source": [
        "#load the data: diabetes dataset provided in the repo\n",
        "data = pd.read_csv('diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_nzAit9A60K"
      },
      "outputs": [],
      "source": [
        "#check the dimensions of the data, and explain why this step is important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIPFwb0SBCHh"
      },
      "outputs": [],
      "source": [
        "#transform the dataset by filling in values that are min = 0 but are not accurate e.g Insulin min=0\n",
        "#chose the best way you think to replace those values, whether with the mean value e.t.c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AAPPovwBcGO"
      },
      "outputs": [],
      "source": [
        "#install missingno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTw5jy8pBeeL"
      },
      "outputs": [],
      "source": [
        "#plot the missingness matrix with missingno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amB1J_ViBWft"
      },
      "outputs": [],
      "source": [
        "#install pandas profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFyCUvhWBY5t"
      },
      "outputs": [],
      "source": [
        "#export an html report for your profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcDHpdyjB07o"
      },
      "outputs": [],
      "source": [
        "#install seaborn and plot at least 2-3 variables of your choice\n",
        "#after plotting explain what the plot is communicating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWHm3x9sCN7U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roPBR22KNeYH"
      },
      "source": [
        "#Further exercises\n",
        "\n",
        "Model spot checking,\n",
        "- I would like for you to choose up to 20 diferent models for classification in the sklearn library and add them in the code below\n",
        "- The idea is to evaluate as many as possible, you can add even more of those.\n",
        "- run them through the code below and then find the ones that might work well with your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP6IYVDfNiTJ",
        "outputId": "0c19303a-c152-4174-cc78-e91a8312579d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Model  F1 Score    Recall  Precision       MCC\n",
            "0           LR  0.628733  0.565837   0.713245  0.475102\n",
            "1          LDA  0.620423  0.555180   0.708347  0.463732\n",
            "2          KNN  0.539798  0.497379   0.601724  0.335675\n",
            "3         CART  0.516083  0.509227   0.529445  0.273097\n",
            "4           NB  0.629839  0.599243   0.669300  0.454409\n",
            "5          SVM  0.576544  0.478453   0.739531  0.444037\n",
            "6           RF  0.636203  0.596695   0.698523  0.476435\n",
            "7           GB  0.630123  0.596746   0.674509  0.455623\n",
            "8          ADA  0.655594  0.630930   0.692205  0.489505\n",
            "9      Bagging  0.595454  0.540476   0.672008  0.420581\n",
            "10  ExtraTrees  0.610236  0.554011   0.693016  0.447786\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, matthews_corrcoef\n",
        "\n",
        "# Load dataset\n",
        "filename = 'diabetes.csv'\n",
        "dataframe = pd.read_csv(filename)\n",
        "\n",
        "# Split the dataset\n",
        "X = dataframe.iloc[:, 0:8]\n",
        "Y = dataframe.iloc[:, 8]\n",
        "\n",
        "# Prepare models\n",
        "models = [\n",
        "    (\"LR\", LogisticRegression(max_iter=1000)),\n",
        "    (\"LDA\", LinearDiscriminantAnalysis()),\n",
        "    (\"KNN\", KNeighborsClassifier()),\n",
        "    (\"CART\", DecisionTreeClassifier()),\n",
        "    (\"NB\", GaussianNB()),\n",
        "    (\"SVM\", SVC(probability=True)),  # Enable probability for SVC to calculate MCC\n",
        "    (\"RF\", RandomForestClassifier()),\n",
        "    (\"GB\", GradientBoostingClassifier()),\n",
        "    (\"ADA\", AdaBoostClassifier()),\n",
        "    (\"Bagging\", BaggingClassifier()),\n",
        "    (\"ExtraTrees\", ExtraTreesClassifier()),\n",
        "]\n",
        "\n",
        "# Scoring metrics\n",
        "scoring = {\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'MCC': make_scorer(matthews_corrcoef)\n",
        "}\n",
        "\n",
        "# Evaluate models function\n",
        "def evaluate_models(models, X, Y, scoring, n_splits=10, random_seed=7):\n",
        "    scores = []\n",
        "    for name, model in models:\n",
        "        kfold = KFold(n_splits=n_splits, random_state=random_seed, shuffle=True)\n",
        "        cv_results = cross_validate(model, X, Y, cv=kfold, scoring=scoring)\n",
        "        scores.append({\n",
        "            'Model': name,\n",
        "            'F1 Score': np.mean(cv_results['test_f1']),\n",
        "            'Recall': np.mean(cv_results['test_recall']),\n",
        "            'Precision': np.mean(cv_results['test_precision']),\n",
        "            'MCC': np.mean(cv_results['test_MCC']),\n",
        "        })\n",
        "    return pd.DataFrame(scores)\n",
        "\n",
        "# Evaluation\n",
        "model_scores = evaluate_models(models, X, Y, scoring)\n",
        "\n",
        "# Display the consolidated scores\n",
        "print(model_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLDAD91IRCy9"
      },
      "outputs": [],
      "source": [
        "#chose your best model and train the model based on the example in the code\n",
        "#For this cell let the parameters in your first model be on default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7467532467532467\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "filename = \"diabetes.csv\"\n",
        "dataframe = pd.read_csv(filename)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (Y)\n",
        "X = dataframe.iloc[:, 0:8]\n",
        "Y = dataframe.iloc[:, 8]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the Logistic Regression model with default parameters\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-FrvukcRL81"
      },
      "outputs": [],
      "source": [
        "#update the parameters as you see fit and record your results\n",
        "#you can run as many examples as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 500}, Accuracy: 0.7662337662337663\n",
            "Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 1000}, Accuracy: 0.7337662337662337\n",
            "Parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}, Accuracy: 0.7597402597402597\n",
            "Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}, Accuracy: 0.7597402597402597\n",
            "Parameters: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 1000}, Accuracy: 0.7532467532467533\n",
            "Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 500}, Accuracy: 0.7337662337662337\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "filename = \"diabetes.csv\"\n",
        "dataframe = pd.read_csv(filename)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (Y)\n",
        "X = dataframe.iloc[:, 0:8]\n",
        "Y = dataframe.iloc[:, 8]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the results dictionary to record the accuracy for each configuration\n",
        "results = {}\n",
        "\n",
        "# Define parameter configurations to try\n",
        "parameters = [\n",
        "    {\n",
        "        \"C\": 0.1,\n",
        "        \"penalty\": \"l1\",\n",
        "        \"solver\": \"liblinear\",\n",
        "        \"max_iter\": 500,\n",
        "    },  # L1 penalty, 'liblinear' solver\n",
        "    {\n",
        "        \"C\": 0.01,\n",
        "        \"penalty\": \"l2\",\n",
        "        \"solver\": \"lbfgs\",\n",
        "        \"max_iter\": 1000,\n",
        "    },  # L2 penalty, 'lbfgs' solver\n",
        "    {\n",
        "        \"C\": 1.0,\n",
        "        \"penalty\": \"l2\",\n",
        "        \"solver\": \"liblinear\",\n",
        "        \"max_iter\": 1000,\n",
        "    },  # L2 penalty, 'liblinear' solver\n",
        "    {\n",
        "        \"C\": 10,\n",
        "        \"penalty\": \"l2\",\n",
        "        \"solver\": \"liblinear\",\n",
        "        \"max_iter\": 1000,\n",
        "    },  # L2 penalty, 'liblinear' solver\n",
        "    {\n",
        "        \"C\": 100,\n",
        "        \"penalty\": \"l2\",\n",
        "        \"solver\": \"liblinear\",\n",
        "        \"max_iter\": 1000,\n",
        "    },  # L2 penalty, 'liblinear' solver\n",
        "    {\n",
        "        \"C\": 0.1,\n",
        "        \"penalty\": \"l2\",\n",
        "        \"solver\": \"lbfgs\",\n",
        "        \"max_iter\": 500,\n",
        "    },  # L2 penalty, 'lbfgs' solver\n",
        "    {\n",
        "        \"C\": 0.01,\n",
        "        \"penalty\": \"l2\",\n",
        "        \"solver\": \"lbfgs\",\n",
        "        \"max_iter\": 1000,\n",
        "    },  # L2 penalty, 'lbfgs' solver\n",
        "]\n",
        "\n",
        "# Train and evaluate the model for each parameter configuration\n",
        "for param_config in parameters:\n",
        "    # Initialize the Logistic Regression model with current parameters\n",
        "    model = LogisticRegression(**param_config)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    Y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "    # Record the accuracy for the current configuration\n",
        "    results[str(param_config)] = accuracy\n",
        "\n",
        "# Display the recorded results\n",
        "for config, accuracy in results.items():\n",
        "    print(f\"Parameters: {config}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_41pqHCRSf_"
      },
      "outputs": [],
      "source": [
        "#Try another model of your choice and repeate the same steps as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "filename = \"diabetes.csv\"\n",
        "dataframe = pd.read_csv(filename)\n",
        "\n",
        "# Split the dataset into features (X) and target variable (Y)\n",
        "X = dataframe.iloc[:, 0:8]\n",
        "Y = dataframe.iloc[:, 8]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the results dictionary to record the accuracy for each configuration\n",
        "results = {}\n",
        "\n",
        "# Define parameter configurations to try\n",
        "parameters = [\n",
        "    {\"n_estimators\": 100, \"max_depth\": 5, \"random_state\": 42},  # Default parameters\n",
        "    {\n",
        "        \"n_estimators\": 50,\n",
        "        \"max_depth\": 10,\n",
        "        \"random_state\": 42,\n",
        "    },  # Decreased n_estimators and increased max_depth\n",
        "    {\n",
        "        \"n_estimators\": 200,\n",
        "        \"max_depth\": 5,\n",
        "        \"random_state\": 42,\n",
        "    },  # Increased n_estimators and default max_depth\n",
        "    {\n",
        "        \"n_estimators\": 100,\n",
        "        \"max_depth\": None,\n",
        "        \"random_state\": 42,\n",
        "    },  # Default n_estimators and no limit on max_depth\n",
        "]\n",
        "\n",
        "# Train and evaluate the model for each parameter configuration\n",
        "for i, param_config in enumerate(parameters):\n",
        "    # Initialize the Random Forest Classifier model with current parameters\n",
        "    model\n",
        "# Display the recorded results\n",
        "for config, accuracy in results.items():\n",
        "    print(f\"Parameters: {config}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8oIHcfWRZ3K"
      },
      "source": [
        "Report:\n",
        "- Write your discoveries in detail and what you have learnt below.\n",
        "- Be as detailed as possible, this is very important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fqvaBsgxRk-J"
      },
      "outputs": [],
      "source": [
        "#apply two transformations to the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hkyRPHxjRqEb"
      },
      "outputs": [],
      "source": [
        "#run model spot checkking again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o0BXiEySRsHa"
      },
      "outputs": [],
      "source": [
        "#which model was the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0fftEZBRxPz"
      },
      "source": [
        "Report:\n",
        "- Write your discoveries in detail and what you have learnt below.\n",
        "- Be as detailed as possible, this is very important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXy2VkJFRuzL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
